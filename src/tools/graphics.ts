import { readFileSync, writeFileSync } from 'fs';
import { Immutable } from 'immer';
import { diffString } from 'json-diff';
import { isEqual } from 'lodash-es';
import {
	Assert,
	AssetGraphicsDefinition,
	AssetGraphicsDefinitionSchema,
	BitField,
	CloneDeepMutable,
	GetLogger,
	LayerDefinition,
	LayerImageOverride,
	LayerImageSetting,
	LayerMirror,
	Logger,
	MakeMirroredPoints,
	MirrorBoneLike,
	ModuleNameSchema,
	PointDefinitionCalculated,
	PointMatchesPointType,
	SCHEME_OVERRIDE,
} from 'pandora-common';
import { relative } from 'path';
import { z } from 'zod';
import { OPTIMIZE_TEXTURES, SRC_DIR, TRY_AUTOCORRECT_WARNINGS } from '../constants.js';
import { GraphicsDatabase } from './graphicsDatabase.js';
import { TriangleRectangleOverlap } from './math/intersections.js';
import { CalculatePointsTriangles } from './math/triangulation.js';
import { DefineImageResource, IImageResource } from './resources.js';
import { AssetGraphicsValidate } from './validation/assetGraphics.js';
import { WatchFile } from './watch.js';

export const GENERATED_RESOLUTIONS: readonly number[] = [0.5, 0.25];

export async function LoadAssetsGraphics(path: string, assetModules: readonly string[]): Promise<AssetGraphicsDefinition> {
	const logger = GetLogger('GraphicsValidation').prefixMessages(`Graphics definition '${relative(SRC_DIR, path)}':\n\t`);

	WatchFile(path);

	const rawDefinition = readFileSync(path, { encoding: 'utf-8' });
	const definition: unknown = JSON.parse(
		rawDefinition
			.split('\n')
			.filter((line) => !line.trimStart().startsWith('//'))
			.join('\n'),
	);

	ModuleNameSchema[SCHEME_OVERRIDE]((module, ctx) => {
		if (!assetModules.includes(module)) {
			ctx.addIssue({
				code: z.ZodIssueCode.custom,
				message: `Module '${module}' is not a valid module name`,
			});
		}
	});

	const parseResult = AssetGraphicsDefinitionSchema.safeParse(definition);

	if (!parseResult.success) {
		logger.error(
			`Not AssetGraphicsDefinition:\n`,
			parseResult.error.toString(),
		);
		throw new Error(`Graphics in '${path}' are not AssetGraphicsDefinition`);
	}

	const canonizedExport = `// THIS IS AN AUTOGENERATED FILE. DO NOT EDIT THIS FILE DIRECTLY.\n`
		+ JSON.stringify(parseResult.data, undefined, '\t').trim()
		+ '\n';
	if (!isEqual(definition, parseResult.data)) {
		Assert(rawDefinition !== canonizedExport);
		const diff = diffString(definition, parseResult.data, { color: false });
		logger.warning('Definition updated during parse:\n', diff);
	} else if (rawDefinition !== canonizedExport) {
		logger.warning(`Definition is not in its canonic form. Please use editor to correct this.`);
	}

	if (rawDefinition !== canonizedExport && TRY_AUTOCORRECT_WARNINGS) {
		writeFileSync(path, canonizedExport, { encoding: 'utf-8' });
		logger.info('The above warning has been auto-corrected; re-run to check if successful.');
	}

	AssetGraphicsValidate(parseResult.data, logger);

	return {
		layers: await Promise.all(parseResult.data.layers.map((l) => LoadAssetLayer(l, logger))),
	};
}

type LayerImageTrimArea = [left: number, top: number, right: number, bottom: number] | null;

function LoadLayerImageResource(image: string): IImageResource {
	return DefineImageResource(image, 'asset', 'png');
}

function LoadLayerImage(image: string, imageTrimArea: LayerImageTrimArea): string {
	let resource = LoadLayerImageResource(image);

	if (imageTrimArea != null) {
		resource = resource.addCutImageRelative(imageTrimArea[0], imageTrimArea[1], imageTrimArea[2], imageTrimArea[3]);
	}

	for (const resolution of GENERATED_RESOLUTIONS) {
		resource.addDownscaledImage(resolution);
	}

	return resource.resultName;
}

function ListLayerImageSettingImages(setting: LayerImageSetting): IImageResource[] {
	const resources = new Set<IImageResource>();

	setting.overrides.forEach(({ image }) => {
		if (image) {
			resources.add(LoadLayerImageResource(image));
		}
	});

	setting.alphaOverrides?.forEach(({ image }) => {
		if (image) {
			resources.add(LoadLayerImageResource(image));
		}
	});

	if (setting.image) {
		resources.add(LoadLayerImageResource(setting.image));
	}
	if (setting.alphaImage) {
		resources.add(LoadLayerImageResource(setting.alphaImage));
	}

	return Array.from(resources);
}

function LoadLayerImageSetting(setting: LayerImageSetting, imageTrimArea: LayerImageTrimArea): LayerImageSetting {
	const overrides: LayerImageOverride[] = setting.overrides
		.map((override) => ({
			...override,
			image: override.image && LoadLayerImage(override.image, imageTrimArea),
		}));
	const alphaOverrides: LayerImageOverride[] | undefined = setting.alphaOverrides
		?.map((override) => ({
			...override,
			image: override.image && LoadLayerImage(override.image, imageTrimArea),
		}));
	return {
		...setting,
		image: setting.image && LoadLayerImage(setting.image, imageTrimArea),
		alphaImage: setting.alphaImage && LoadLayerImage(setting.alphaImage, imageTrimArea),
		overrides,
		alphaOverrides,
	};
}

async function LoadAssetLayer(layer: LayerDefinition, logger: Logger): Promise<LayerDefinition> {
	logger = logger.prefixMessages(`[Layer ${layer.name ?? '[unnamed]'}]`);

	const pointTemplate = GraphicsDatabase.getPointTemplate(layer.points);

	if (pointTemplate == null) {
		throw new Error(`Layer ${layer.name ?? '[unnamed]'} refers to unknown template '${layer.points}'`);
	}

	// Check if the image has any UV pose manipulation or not
	let hasUvManipulation: boolean = false;
	if (layer.scaling != null) {
		hasUvManipulation = true;
		if (layer.scaling.stops.length === 0) {
			logger.warning(`Has scaling enabled, but no scaling stops. Disable the scaling altogether if it isn't needed`);
		}
	}
	if (layer.image.uvPose != null) {
		hasUvManipulation = true;
	}
	for (const imageOverride of [...layer.image.overrides, ...(layer.image.alphaOverrides ?? [])]) {
		if (imageOverride.uvPose != null) {
			hasUvManipulation = true;
		}
	}

	let layerPointFilterMask = layer.pointFilterMask;
	let imageTrimArea: LayerImageTrimArea = null;
	if (!OPTIMIZE_TEXTURES) {
		// NOOP
	} else if (hasUvManipulation) {
		logger.debug('Layer has UV manipulation, skipping texture optimization');
	} else {
		// Get all the images and their bounding boxes for this layer
		const images = Array.from(new Set([
			...ListLayerImageSettingImages(layer.image),
			...(layer.scaling ? layer.scaling.stops.flatMap((stop) => ListLayerImageSettingImages(stop[1])) : []),
		]));
		const boundingBoxes = await Promise.all(images.map((i) => i.getContentBoundingBox()));
		// Calculate total image bounding boxes
		const imageBoundingBox = [1, 1, 0, 0]; // left, top, rightExclusive, bottomExclusive
		for (const image of boundingBoxes) {
			if (image.width === 0 || image.height === 0)
				continue;
			imageBoundingBox[0] = Math.min(imageBoundingBox[0], image.left / image.width);
			imageBoundingBox[1] = Math.min(imageBoundingBox[1], image.top / image.height);
			imageBoundingBox[2] = Math.max(imageBoundingBox[2], image.rightExclusive / image.width);
			imageBoundingBox[3] = Math.max(imageBoundingBox[3], image.bottomExclusive / image.height);
		}

		if (!(imageBoundingBox[0] < imageBoundingBox[2]) || !(imageBoundingBox[1] < imageBoundingBox[3])) {
			logger.warning('All layer\'s images are empty. This will produce empty mesh.');
			imageBoundingBox[0] = 0;
			imageBoundingBox[1] = 0;
		}

		// Calculate the actual points first (such as resolving mirrored points)
		const calculatedPoints: Immutable<PointDefinitionCalculated[]> = pointTemplate
			.map((point, index): PointDefinitionCalculated => ({
				...CloneDeepMutable(point),
				index,
				isMirror: false,
			}))
			.flatMap(MakeMirroredPoints);

		// Calculate layer's point types (including mirrored ones)
		let pointTypes = layer.pointType;
		if (layer.mirror !== LayerMirror.NONE && pointTypes != null) {
			pointTypes = [
				...pointTypes,
				...pointTypes.map(MirrorBoneLike),
			];
		}

		// Calculate point type filter
		const pointTypeFilter = new BitField(calculatedPoints.length);
		for (let i = 0; i < calculatedPoints.length; i++) {
			pointTypeFilter.set(i, PointMatchesPointType(calculatedPoints[i], pointTypes));
		}
		// Apply existing point filter mask
		if (layerPointFilterMask != null) {
			const existingMask = new BitField(new Uint8Array(Buffer.from(layerPointFilterMask, 'base64')));
			if (existingMask.length < calculatedPoints.length) {
				logger.error(`Invalid pointFilterMask specified: Length ${existingMask.length} is smaller than point count (${calculatedPoints.length})`);
			} else {
				for (let i = 0; i < calculatedPoints.length; i++) {
					if (!existingMask.get(i)) {
						pointTypeFilter.set(i, false);
					}
				}
			}
		}

		// Generate the mesh triangles
		const triangles = CalculatePointsTriangles(calculatedPoints, pointTypeFilter);

		// Calculate which points are relevant to the image, excluding those that aren't
		const pointFilter = new BitField(calculatedPoints.length);
		{
			// Rectangle corners for nicer calculation
			const x1 = Math.floor(layer.x + imageBoundingBox[0] * layer.width);
			const y1 = Math.floor(layer.y + imageBoundingBox[1] * layer.height);
			const x2 = Math.ceil(layer.x + imageBoundingBox[2] * layer.width) - 1;
			const y2 = Math.ceil(layer.y + imageBoundingBox[3] * layer.height) - 1;

			// For each triangle determinate if it has intersection with the rectangle
			for (const [a, b, c] of triangles) {
				if (TriangleRectangleOverlap([calculatedPoints[a].pos, calculatedPoints[b].pos, calculatedPoints[c].pos], [x1, y1, x2, y2])) {
					pointFilter.set(a, true);
					pointFilter.set(b, true);
					pointFilter.set(c, true);

					// All the points above should have already passed point type filter to reach this place
					Assert(pointTypeFilter.get(a));
					Assert(pointTypeFilter.get(b));
					Assert(pointTypeFilter.get(c));
				}
			}
		}

		// Check if the point filter needs to be saved
		let layerPointFilterMaskNeedsSave = false;
		for (let i = 0; i < calculatedPoints.length; i++) {
			if (pointTypeFilter.get(i) !== pointFilter.get(i)) {
				layerPointFilterMaskNeedsSave = true;
				break;
			}
		}
		if (layerPointFilterMaskNeedsSave) {
			layerPointFilterMask = Buffer.from(pointFilter.buffer).toString('base64');
		}

		// Calculate bounding box of remaining points
		// Inverse values by default, as we go through points
		imageTrimArea = [layer.width, layer.height, 0, 0]; // left, top, rightExclusive, bottomExclusive

		for (let i = 0; i < calculatedPoints.length; i++) {
			const point = calculatedPoints[i];
			// Filter points based on previous findings
			if (!pointFilter.get(i))
				continue;

			// Remap point to layerspace
			const x = (point.pos[0] - (layer.x));
			const y = (point.pos[1] - (layer.y));
			// Recalculate minimums and maximums found
			imageTrimArea[0] = Math.min(imageTrimArea[0], x); // left
			imageTrimArea[1] = Math.min(imageTrimArea[1], y); // top
			imageTrimArea[2] = Math.max(imageTrimArea[2], x); // right
			imageTrimArea[3] = Math.max(imageTrimArea[3], y); // bottom
		}
		// Check against bad conditions
		Assert(imageTrimArea[0] <= layer.width);
		Assert(imageTrimArea[1] <= layer.height);
		Assert(imageTrimArea[2] >= 0);
		Assert(imageTrimArea[3] >= 0);

		if (!(imageTrimArea[0] < imageTrimArea[2])) {
			logger.warning('Trim area has non-positive width. Does the layer have no useful triangles?');
			imageTrimArea = null;
		} else if (!(imageTrimArea[1] < imageTrimArea[3])) {
			logger.warning('Trim area has non-positive height. Does the layer have no useful triangles?');
			imageTrimArea = null;
		} else if (imageTrimArea[0] < 0 || imageTrimArea[1] < 0 || imageTrimArea[2] > layer.width || imageTrimArea[3] > layer.height) {
			// TODO: Un-silence this once current problems are fixed
			// logger.warning(
			//    'Layer does not cover the used part of the mesh. This might cause graphical glitches.\n' +
			//    '\tOverflow:\n' +
			//    (imageTrimArea[0] < 0 ? `\t\tLeft: ${-imageTrimArea[0]}\n` : '') +
			//    (imageTrimArea[1] < 0 ? `\t\tTop: ${-imageTrimArea[1]}\n` : '') +
			//    (imageTrimArea[2] > layer.width ? `\t\tRight: ${(imageTrimArea[2] - layer.width)}\n` : '') +
			//    (imageTrimArea[3] > layer.height ? `\t\tBottom: ${(imageTrimArea[3] - layer.height)}\n` : ''),
			// );
			imageTrimArea = null;
		}
	}

	const normalizedImageTrimArea: LayerImageTrimArea = imageTrimArea != null ? [
		imageTrimArea[0] / layer.width,
		imageTrimArea[1] / layer.height,
		imageTrimArea[2] / layer.width,
		imageTrimArea[3] / layer.height,
	] : null;

	const result: LayerDefinition = {
		...layer,
		pointFilterMask: layerPointFilterMask,
		image: LoadLayerImageSetting(layer.image, normalizedImageTrimArea),
		scaling: layer.scaling && {
			scaleBone: layer.scaling.scaleBone,
			stops: layer.scaling.stops.map((stop) => [stop[0], LoadLayerImageSetting(stop[1], normalizedImageTrimArea)]),
		},
	};
	// Adjust layer size of we trimmed it down
	if (imageTrimArea != null) {
		const left = imageTrimArea[0];
		const top = imageTrimArea[1];
		result.x += left;
		result.y += top;

		result.width = imageTrimArea[2] - left;
		result.height = imageTrimArea[3] - top;
	}

	return result;
}
